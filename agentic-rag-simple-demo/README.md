# ðŸ¤– Agentic RAG - Intelligent Retrieval-Augmented Generation

A practical demonstration of **Agentic RAG** where an AI agent intelligently decides WHEN to retrieve from a knowledge base, unlike basic RAG which always retrieves.

## ðŸŽ¯ What is Agentic RAG?

### Basic RAG (Traditional)
```
User Query â†’ ALWAYS Retrieve â†’ Generate Answer
```
- âŒ Retrieves even for simple questions ("Hi!")
- âŒ Slower (unnecessary vector search)
- âŒ More expensive (extra API calls)

### Agentic RAG (This Example)
```
User Query â†’ Agent Decides â†’ Retrieve if needed â†’ Generate Answer
```
- âœ… Only retrieves when necessary
- âœ… Faster for simple queries
- âœ… More cost-effective
- âœ… Better user experience

## ðŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User Query  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Agent (LLM)        â”‚
â”‚  - Analyzes query   â”‚
â”‚  - Decides action   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚             â”‚
       â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Respond  â”‚   â”‚ Retrieve     â”‚
â”‚ Directly â”‚   â”‚ from Vector  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ Store        â”‚
               â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚ Synthesize   â”‚
               â”‚ Answer       â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âœ¨ Key Features

- ðŸ§  **Intelligent Decision Making** - Agent decides when retrieval is needed
- ðŸ“š **Vector Store** - FAISS for semantic search
- ðŸ” **Similarity Search** - Find most relevant documents
- ðŸ’¬ **Natural Conversation** - Handles greetings, follow-ups, technical questions
- ðŸ“Š **Retrieval Tracking** - See when retrieval was used
- ðŸŽ¯ **Real-world Use Case** - LangGraph documentation Q&A

## ðŸš€ Quick Start

### 1. Install Dependencies

```bash
uv sync
```

### 2. Set Up Environment

```bash
cp .env.example .env
```

Edit `.env` and add your OpenAI API key:
```env
OPENAI_API_KEY=sk-proj-your_key_here
```

### 3. Run the Demo

```bash
source .venv/bin/activate
python main.py
```

### 4. Verify Retrieval Behavior (Optional)

```bash
# Quick verification (6 tests)
python verify_retrieval.py

# Comprehensive test suite (14 tests)
python test_agentic_rag.py
```

See [TESTING.md](TESTING.md) for detailed testing guide.

## ðŸ’¬ Example Queries

The demo runs 6 test queries demonstrating intelligent retrieval:

### âŒ No Retrieval Needed

**Query 1:** "Hi! How are you today?"
- **Agent Decision:** Respond directly
- **Why:** General greeting, no technical info needed
- **Result:** Fast, direct response

**Query 4:** "What's 2 + 2?"
- **Agent Decision:** Respond directly
- **Why:** General knowledge
- **Result:** No need to search docs

**Query 6:** "Thanks for your help!"
- **Agent Decision:** Respond directly
- **Why:** Acknowledgment
- **Result:** Polite response

### âœ… Retrieval Needed

**Query 2:** "What is LangGraph and what are its key features?"
- **Agent Decision:** Retrieve from docs
- **Why:** Specific technical question
- **Result:** Accurate, grounded answer

**Query 3:** "How do I create a StateGraph?"
- **Agent Decision:** Retrieve from docs
- **Why:** API/implementation question
- **Result:** Code examples and instructions

**Query 5:** "Explain checkpointers and persistence in LangGraph"
- **Agent Decision:** Retrieve from docs
- **Why:** Specific concept explanation
- **Result:** Detailed technical answer

## ðŸ“Š Expected Output

```
================================================================================
AGENTIC RAG DEMO - Agent Decides When to Retrieve
================================================================================

ðŸ“š Creating knowledge base...
   Split into 12 chunks
   âœ… Vector store created with 12 chunks

================================================================================
ðŸ“‹ Query 1/6
================================================================================
Question: "Hi! How are you today?"
Expected: No retrieval (general greeting)
--------------------------------------------------------------------------------

ðŸ’¬ Response: Hello! I'm here and ready to help you with any questions...

ðŸ“Š Retrieval used: âŒ NO

================================================================================
ðŸ“‹ Query 2/6
================================================================================
Question: "What is LangGraph and what are its key features?"
Expected: Retrieval needed (specific technical question)
--------------------------------------------------------------------------------

ðŸ” Retrieving docs for: 'What is LangGraph and what are its key features?'
   âœ… Retrieved 2 relevant documents

ðŸ’¬ Response: LangGraph is a framework for building stateful, multi-actor...

ðŸ“Š Retrieval used: âœ… YES
```

## ðŸ” How It Works

### Step 1: Create Knowledge Base

```python
# Sample documents about LangGraph
documents = [
    Document(page_content="LangGraph is a framework..."),
    Document(page_content="StateGraph is the main..."),
    # ... more documents
]

# Split into chunks
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=50
)
splits = text_splitter.split_documents(documents)

# Create vector store
vectorstore = FAISS.from_documents(splits, embeddings)
```

### Step 2: Create Retrieval Tool

```python
@tool
def retrieve_langgraph_docs(query: str) -> str:
    """Search the LangGraph documentation"""
    docs = vectorstore.similarity_search(query, k=2)
    return format_results(docs)
```

### Step 3: Create Agent with Decision Making

```python
agent = create_react_agent(
    model,
    tools=[retrieve_langgraph_docs],
    prompt="""You are a helpful assistant.

IMPORTANT:
1. For general questions, respond directly WITHOUT tools
2. For technical questions, USE the retrieve_langgraph_docs tool
3. Only retrieve when you need specific information"""
)
```

## ðŸŽ“ Key Concepts Demonstrated

### 1. Vector Store (FAISS)
- Stores document embeddings
- Enables semantic search
- Fast similarity matching

### 2. Text Chunking
- Splits documents into manageable pieces
- Overlapping chunks for context
- Optimized for retrieval

### 3. Agent Decision Making
- LLM analyzes the query
- Decides if retrieval is needed
- Chooses appropriate action

### 4. Tool Calling
- Agent has access to retrieval tool
- Calls tool only when needed
- Synthesizes retrieved information

## ðŸ“ˆ Performance Comparison

| Scenario | Basic RAG | Agentic RAG |
|----------|-----------|-------------|
| **"Hi!"** | Retrieves (slow) | Direct response (fast) |
| **"What is X?"** | Retrieves (good) | Retrieves (good) |
| **"Thanks!"** | Retrieves (waste) | Direct response (efficient) |
| **Cost** | Higher | Lower |
| **Speed** | Slower | Faster (for simple queries) |
| **Accuracy** | Good | Good (when needed) |

## ðŸŽ¯ When to Use Agentic RAG

### âœ… Use Agentic RAG When:
- Mix of simple and complex queries
- Cost optimization is important
- Speed matters for simple questions
- You want natural conversation flow
- Users ask greetings, follow-ups, etc.

### âŒ Use Basic RAG When:
- ALL queries need retrieval
- Simplicity is more important
- You have very few queries
- Every query is technical

## ðŸ”§ Customization

### Add Your Own Documents

```python
# Load from web
from langchain_community.document_loaders import WebBaseLoader
loader = WebBaseLoader("https://your-docs.com")
docs = loader.load()

# Or load from files
from langchain_community.document_loaders import TextLoader
loader = TextLoader("your_docs.txt")
docs = loader.load()
```

### Adjust Retrieval Parameters

```python
# Change number of documents retrieved
docs = vectorstore.similarity_search(query, k=3)  # Get 3 instead of 2

# Change chunk size
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,  # Larger chunks
    chunk_overlap=100
)
```

### Modify Agent Behavior

```python
# Make agent more/less likely to retrieve
prompt="""You are a helpful assistant.

IMPORTANT:
1. ALWAYS use retrieval for ANY technical question  # More aggressive
2. Only use retrieval for very specific questions    # More conservative
"""
```

## ðŸ†š Comparison with Your Subgraph Example

| Feature | Subgraph Pattern | Agentic RAG |
|---------|-----------------|-------------|
| **Focus** | Routing & modularity | Intelligent retrieval |
| **State** | Different schemas per team | Tracks retrieval usage |
| **Decision** | Route to teams | Retrieve or not |
| **Use Case** | Multi-team systems | Knowledge base Q&A |
| **Complexity** | Higher | Lower |

**Can Combine:** Use Agentic RAG WITHIN a subgraph! For example, your tech support subgraph could use Agentic RAG for its knowledge base search.

## ðŸ’¡ Next Steps

### 1. Integrate with Your Subgraph
```python
# In your tech support subgraph
@tool
def search_knowledge_base_smart(query: str) -> str:
    """Use agentic RAG instead of keyword search"""
    return retrieve_langgraph_docs(query)
```

### 2. Add More Documents
- Load your actual documentation
- Add product manuals
- Include FAQs

### 3. Improve Retrieval
- Try different embedding models
- Experiment with chunk sizes
- Add metadata filtering

### 4. Add Persistence
- Save vector store to disk
- Cache embeddings
- Use PostgreSQL for production

## ðŸ“š Learn More

- **LangGraph Docs:** https://langchain-ai.github.io/langgraph/
- **FAISS:** https://github.com/facebookresearch/faiss
- **LangChain RAG:** https://python.langchain.com/docs/tutorials/rag/
- **Your Subgraph Example:** `../supervisor-subgraph-pattern-demo-langgraph/`

## ðŸŽ“ Key Takeaways

1. **Agentic RAG = Smart Retrieval** - Agent decides when to retrieve
2. **Better UX** - Fast responses for simple queries
3. **Cost Effective** - Only retrieve when needed
4. **Easy to Implement** - Just add retrieval as a tool
5. **Production Ready** - Use with real documentation

---

**Built with LangGraph** ðŸ¦œðŸ”—