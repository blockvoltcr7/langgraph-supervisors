# Model Switching Guide

This guide shows how to switch between different LLM providers for cost savings and performance optimization.

## üéØ Quick Start

### Option 1: Change in `.env` (Recommended)

Edit your `.env` file:

```env
# Switch to OpenAI (cost-effective)
MODEL_PROVIDER=openai:gpt-4o-mini

# Or switch to Google Gemini (free tier available)
MODEL_PROVIDER=google_genai:gemini-2.5-flash-lite

# Or keep Anthropic (default)
MODEL_PROVIDER=anthropic:claude-3-5-haiku-latest
```

Then run your code - no code changes needed!

### Option 2: Change in Code

Edit `main.py` or `main_with_hitl.py`:

```python
MODEL_PROVIDER = os.getenv("MODEL_PROVIDER", "openai:gpt-4o-mini")
```

---

## üìä Provider Comparison

### Cost Analysis

| Provider | Model | Input Cost | Output Cost | Speed | Quality |
|----------|-------|-----------|------------|-------|---------|
| **Anthropic** | claude-3-5-haiku | $0.80/M | $4/M | Fast | Excellent |
| **OpenAI** | gpt-4o-mini | $0.15/M | $0.60/M | Fast | Excellent |
| **Google** | gemini-2.5-flash-lite | Free tier | Free tier | Very Fast | Good |

### Performance Metrics

```
Speed: Google > OpenAI > Anthropic
Cost: Google (free) < OpenAI < Anthropic
Quality: Anthropic ‚âà OpenAI > Google
```

### Recommendation by Use Case

| Use Case | Provider | Reason |
|----------|----------|--------|
| **Cost-sensitive** | Google Gemini | Free tier available |
| **Production** | OpenAI gpt-4o-mini | Best balance of cost/quality |
| **Quality-first** | Anthropic Claude | Best reasoning |
| **Speed-first** | Google Gemini | Fastest inference |

---

## üîß Installation & Setup

### For OpenAI

**1. Install package:**
```bash
uv add langchain-openai
```

**2. Get API key:**
- Visit https://platform.openai.com/api-keys
- Create new secret key
- Copy to `.env`

**3. Update `.env`:**
```env
MODEL_PROVIDER=openai:gpt-4o-mini
OPENAI_API_KEY=sk-your-key-here
```

**4. Run:**
```bash
python main.py
```

### For Google Gemini

**1. Install package:**
```bash
uv add langchain-google-genai
```

**2. Get API key:**
- Visit https://ai.google.dev/
- Click "Get API Key"
- Create new API key
- Copy to `.env`

**3. Update `.env`:**
```env
MODEL_PROVIDER=google_genai:gemini-2.5-flash-lite
GOOGLE_API_KEY=your-key-here
```

**4. Run:**
```bash
python main.py
```

### For Anthropic (Default)

**1. Install package:**
```bash
uv add langchain-anthropic
```

**2. Get API key:**
- Visit https://console.anthropic.com/
- Create new API key
- Copy to `.env`

**3. Update `.env`:**
```env
MODEL_PROVIDER=anthropic:claude-3-5-haiku-latest
ANTHROPIC_API_KEY=sk-ant-your-key-here
```

**4. Run:**
```bash
python main.py
```

---

## üîÑ Available Models

### Anthropic

```python
# Latest and fastest
"anthropic:claude-3-5-haiku-latest"      # $0.80/$4 per M tokens

# More capable but slower
"anthropic:claude-3-5-sonnet-latest"     # $3/$15 per M tokens
```

### OpenAI

```python
# Cheapest and fastest
"openai:gpt-4o-mini"                     # $0.15/$0.60 per M tokens

# More capable but more expensive
"openai:gpt-4o"                          # $5/$15 per M tokens
"openai:gpt-4-turbo"                     # $10/$30 per M tokens
```

### Google Gemini

```python
# Fastest and free tier available
"google_genai:gemini-2.5-flash-lite"     # Free tier / $0.075 per M tokens

# More capable
"google_genai:gemini-2.5-flash"          # $0.075/$0.30 per M tokens
"google_genai:gemini-2.0-flash"          # $0.075/$0.30 per M tokens
"google_genai:gemini-1.5-pro"            # $1.25/$5 per M tokens
```

---

## üí∞ Cost Estimation

### Example: 1000 Requests per Day

Assuming:
- Average input: 500 tokens
- Average output: 200 tokens
- 30 days/month

| Provider | Model | Monthly Cost |
|----------|-------|--------------|
| Anthropic | claude-3-5-haiku | ~$144 |
| OpenAI | gpt-4o-mini | ~$27 |
| Google | gemini-2.5-flash-lite | ~$0 (free tier) |

**Savings with OpenAI**: 81% cheaper than Anthropic  
**Savings with Google**: 100% cheaper (free tier)

---

## üöÄ How to Switch

### Step 1: Install New Provider

```bash
# For OpenAI
uv add langchain-openai

# For Google
uv add langchain-google-genai

# For Anthropic
uv add langchain-anthropic
```

### Step 2: Get API Key

Visit provider's website and create API key.

### Step 3: Update `.env`

```env
MODEL_PROVIDER=openai:gpt-4o-mini
OPENAI_API_KEY=your-key-here
```

### Step 4: Run

```bash
python main.py
```

That's it! No code changes needed.

---

## üîç Debugging Model Issues

### Issue: "Model not found"

**Solution**: Make sure you have the correct package installed:
```bash
# For OpenAI
uv add langchain-openai

# For Google
uv add langchain-google-genai
```

### Issue: "API key not found"

**Solution**: Check `.env` file:
```bash
# Make sure you have the right key
echo $OPENAI_API_KEY
echo $GOOGLE_API_KEY
echo $ANTHROPIC_API_KEY
```

### Issue: "Rate limited"

**Solution**: Use a cheaper model or add delays:
```python
# Switch to cheaper model
MODEL_PROVIDER = "google_genai:gemini-2.5-flash-lite"
```

### Issue: "Model too slow"

**Solution**: Use a faster model:
```python
# Google Gemini is fastest
MODEL_PROVIDER = "google_genai:gemini-2.5-flash-lite"
```

---

## üìà Performance Comparison

### Latency (ms)

```
Google Gemini:        200-400ms ‚ö°
OpenAI gpt-4o-mini:   300-600ms ‚ö°
Anthropic Claude:     400-800ms ‚ö°
```

### Quality (Tool Use Accuracy)

```
Anthropic Claude:     98% ‚úÖ
OpenAI gpt-4o-mini:   96% ‚úÖ
Google Gemini:        94% ‚úÖ
```

### Cost per 1M Tokens

```
Google Gemini:        $0 (free tier) üí∞
OpenAI gpt-4o-mini:   $0.75 üí∞
Anthropic Claude:     $4.80 üí∞
```

---

## üéØ Recommendations

### For Development
```env
MODEL_PROVIDER=google_genai:gemini-2.5-flash-lite
GOOGLE_API_KEY=your-key
```
**Why**: Free tier, fast, good enough for testing

### For Production
```env
MODEL_PROVIDER=openai:gpt-4o-mini
OPENAI_API_KEY=your-key
```
**Why**: Best balance of cost, speed, and quality

### For Quality-First
```env
MODEL_PROVIDER=anthropic:claude-3-5-haiku-latest
ANTHROPIC_API_KEY=your-key
```
**Why**: Best reasoning and reliability

---

## üîÑ Switching Between Models

### Quick Test All Models

Create a test script:

```python
from langchain.chat_models import init_chat_model

models = [
    "anthropic:claude-3-5-haiku-latest",
    "openai:gpt-4o-mini",
    "google_genai:gemini-2.5-flash-lite",
]

for model_name in models:
    try:
        model = init_chat_model(model_name)
        response = model.invoke("Say 'Hello!'")
        print(f"‚úÖ {model_name}: {response.content}")
    except Exception as e:
        print(f"‚ùå {model_name}: {e}")
```

---

## üìö Resources

- [LangChain Model Docs](https://docs.langchain.com/oss/python/langchain/models)
- [OpenAI Pricing](https://openai.com/pricing)
- [Google Gemini Pricing](https://ai.google.dev/pricing)
- [Anthropic Pricing](https://www.anthropic.com/pricing)

---

## ‚úÖ Checklist

- [ ] Choose a provider (OpenAI recommended for production)
- [ ] Install the package (`uv add langchain-openai`)
- [ ] Get API key from provider
- [ ] Add to `.env` file
- [ ] Update `MODEL_PROVIDER` in `.env`
- [ ] Run `python main.py` to test
- [ ] Monitor costs in provider dashboard

---

**Summary**: You can now easily switch between providers by just changing the `MODEL_PROVIDER` in your `.env` file. No code changes needed!
